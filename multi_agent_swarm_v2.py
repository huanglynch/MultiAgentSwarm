import yaml
import logging
import os
import glob
import importlib.util
import requests
import random
import time
import threading
import base64
import mimetypes
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional
from openai import OpenAI
import json
from datetime import datetime
import chromadb
from chromadb.utils import embedding_functions
from duckduckgo_search import DDGS
# ====================== æ—¶é—´ç»Ÿè®¡å·¥å…· ======================
from contextlib import contextmanager
from datetime import datetime
import time


class TimeTracker:
    """æ—¶é—´ç»Ÿè®¡å·¥å…·ç±»"""

    def __init__(self):
        self.start_time = None
        self.checkpoints = {}

    def start(self):
        """å¼€å§‹è®¡æ—¶"""
        self.start_time = time.time()
        return self.start_time

    def checkpoint(self, name: str):
        """è®°å½•æ£€æŸ¥ç‚¹"""
        if self.start_time is None:
            self.start()
        elapsed = time.time() - self.start_time
        self.checkpoints[name] = elapsed
        return elapsed

    def get_elapsed(self) -> float:
        """è·å–æ€»è€—æ—¶"""
        if self.start_time is None:
            return 0
        return time.time() - self.start_time

    def format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.2f}ç§’"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            secs = seconds % 60
            return f"{minutes}åˆ†{secs:.1f}ç§’"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = seconds % 60
            return f"{hours}å°æ—¶{minutes}åˆ†{secs:.0f}ç§’"

    def summary(self) -> str:
        """ç”Ÿæˆè€—æ—¶æ‘˜è¦"""
        total = self.get_elapsed()
        lines = [f"\n{'=' * 60}"]
        lines.append(f"â±ï¸  æ€»è€—æ—¶: {self.format_time(total)}")
        lines.append(f"{'â”€' * 60}")

        if self.checkpoints:
            lines.append("ğŸ“Š å„é˜¶æ®µè€—æ—¶:")
            for name, elapsed in self.checkpoints.items():
                percentage = (elapsed / total * 100) if total > 0 else 0
                lines.append(f"   {name}: {self.format_time(elapsed)} ({percentage:.1f}%)")

        lines.append(f"{'=' * 60}")
        return "\n".join(lines)

@contextmanager
def timer(description: str):
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šè‡ªåŠ¨è®¡æ—¶å¹¶æ‰“å°"""
    start = time.time()
    print(f"â±ï¸  å¼€å§‹: {description}", flush=True)
    try:
        yield
    finally:
        elapsed = time.time() - start
        print(f"âœ… å®Œæˆ: {description} | è€—æ—¶: {TimeTracker().format_time(elapsed)}", flush=True)



# ====================== çº¿ç¨‹å®‰å…¨çš„å·¥å…·ç¼“å­˜ ======================
tool_cache = {}
cache_count = 0
cache_lock = threading.Lock()


def clean_cache():
    """è‡ªåŠ¨æ¸…ç†å·¥å…·ç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    global cache_count
    with cache_lock:
        if cache_count > 50:
            tool_cache.clear()
            cache_count = 0
            logging.info("ğŸ§¹ è‡ªåŠ¨æ¸…ç†å·¥å…·ç¼“å­˜")


# ====================== å·¥å…·å‡½æ•° ======================
def web_search(query: str, num_results: int = 5) -> str:
    """DuckDuckGo ç½‘é¡µæœç´¢ï¼ˆå¸¦ç¼“å­˜ + éšæœºå»¶æ—¶ï¼‰"""
    global cache_count
    clean_cache()

    with cache_lock:
        if query in tool_cache:
            return tool_cache[query]

    time.sleep(random.uniform(0.5, 2.0))

    try:
        with DDGS() as ddgs:
            results = [r for r in ddgs.text(query, max_results=num_results)]

        result = "\n".join([
            f"æ ‡é¢˜: {r['title']}\næ‘˜è¦: {r['body']}\né“¾æ¥: {r['href']}"
            for r in results
        ])

        with cache_lock:
            tool_cache[query] = result
            cache_count += 1

        return result
    except Exception as e:
        logging.error(f"æœç´¢å¤±è´¥: {e}")
        return f"æœç´¢å¤±è´¥: {str(e)}"


def browse_page(url: str) -> str:
    """æµè§ˆç½‘é¡µå¹¶æå–æ–‡æœ¬ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global cache_count
    clean_cache()

    with cache_lock:
        if url in tool_cache:
            return tool_cache[url]

    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=10)
        resp.raise_for_status()

        soup = BeautifulSoup(resp.text, "html.parser")
        for script in soup(["script", "style"]):
            script.decompose()

        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        result = "\n".join(chunk for chunk in chunks if chunk)

        with cache_lock:
            tool_cache[url] = result
            cache_count += 1

        return result
    except Exception as e:
        logging.error(f"æµè§ˆå¤±è´¥ {url}: {e}")
        return f"æµè§ˆå¤±è´¥: {str(e)}"


def run_python(code: str) -> str:
    """
    æ²™ç®±æ‰§è¡Œ Python ä»£ç ï¼ˆ10ç§’è¶…æ—¶ï¼‰
    æ³¨æ„ï¼šthreading.Timer æ— æ³•çœŸæ­£ç»ˆæ­¢é˜»å¡ä»£ç ï¼Œä»…ä½œè½¯è¶…æ—¶
    """
    result_container = {"output": None, "done": False}

    def target():
        try:
            restricted_globals = {
                "__builtins__": {
                    "print": print,
                    "range": range,
                    "len": len,
                    "str": str,
                    "int": int,
                    "float": float,
                    "list": list,
                    "dict": dict,
                    "sum": sum,
                    "min": min,
                    "max": max,
                }
            }
            local_vars = {}
            exec(code, restricted_globals, local_vars)
            result_container["output"] = str(local_vars.get("result", "æ‰§è¡ŒæˆåŠŸï¼Œæ— è¿”å›ç»“æœ"))
        except Exception as e:
            result_container["output"] = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
        finally:
            result_container["done"] = True

    thread = threading.Thread(target=target, daemon=True)
    thread.start()
    thread.join(timeout=10.0)

    if not result_container["done"]:
        return "â±ï¸ æ‰§è¡Œè¶…æ—¶ï¼ˆ10ç§’ï¼‰"

    return result_container["output"]


# ====================== å‘é‡è®°å¿† ======================
class VectorMemory:
    """åŸºäº ChromaDB çš„å‘é‡è®°å¿†å­˜å‚¨"""

    def __init__(self, persist_directory: str = "./memory_db"):
        try:
            self.client = chromadb.PersistentClient(path=persist_directory)
            self.collection = self.client.get_or_create_collection(
                name="swarm_memory",
                embedding_function=embedding_functions.DefaultEmbeddingFunction()
            )
            logging.info("âœ… å‘é‡è®°å¿†æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"å‘é‡è®°å¿†åˆå§‹åŒ–å¤±è´¥: {e}")
            self.collection = None

    def add(self, text: str, metadata: Optional[Dict] = None):
        """æ·»åŠ è®°å¿†"""
        if not self.collection:
            return

        if not metadata:
            metadata = {"timestamp": datetime.now().isoformat()}

        try:
            self.collection.add(
                documents=[text],
                metadatas=[metadata],
                ids=[f"{datetime.now().timestamp()}"]
            )
        except Exception as e:
            logging.error(f"æ·»åŠ è®°å¿†å¤±è´¥: {e}")

    def search(self, query: str, n_results: int = 5) -> str:
        """æœç´¢ç›¸å…³è®°å¿†"""
        if not self.collection:
            return ""

        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=n_results
            )
            if results and results["documents"]:
                return "\n\n---\n\n".join(results["documents"][0])
        except Exception as e:
            logging.error(f"æœç´¢è®°å¿†å¤±è´¥: {e}")

        return ""


# ====================== Skill åŠ¨æ€åŠ è½½å™¨ ======================
def load_skills(skills_dir: str = "skills"):
    """
    é€’å½’åŠ è½½ skills ç›®å½•ä¸‹çš„æ‰€æœ‰ Python å·¥å…·å’Œ Markdown çŸ¥è¯†æ–‡ä»¶
    æ”¯æŒå­ç›®å½•ç»“æ„ï¼Œä¾‹å¦‚ï¼š
    skills/
    â”œâ”€â”€ file/
    â”‚   â”œâ”€â”€ read_file.py
    â”‚   â””â”€â”€ write_file.py
    â”œâ”€â”€ web/
    â”‚   â””â”€â”€ web_search.py
    â””â”€â”€ knowledge/
        â””â”€â”€ ai_basics.md
    """
    tool_registry = {}
    shared_knowledge = []

    if not os.path.exists(skills_dir):
        logging.warning(f"âš ï¸ Skills ç›®å½•ä¸å­˜åœ¨: {skills_dir}")
        return tool_registry, ""  # âœ… è¿”å›ç©ºå­—ç¬¦ä¸²

    # âœ… é€’å½’æ‰«ææ‰€æœ‰ .py æ–‡ä»¶
    py_files = glob.glob(os.path.join(skills_dir, "**/*.py"), recursive=True)

    for py_file in py_files:
        try:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
            rel_path = os.path.relpath(py_file, skills_dir)

            # åŠ¨æ€å¯¼å…¥æ¨¡å—
            spec = importlib.util.spec_from_file_location(
                os.path.splitext(os.path.basename(py_file))[0],
                py_file
            )
            mod = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(mod)

            # æŸ¥æ‰¾å·¥å…·å‡½æ•°å’Œ schema
            if hasattr(mod, "tool_function") and hasattr(mod, "tool_schema"):
                tool_name = mod.tool_schema["function"]["name"]
                tool_registry[tool_name] = {
                    "func": mod.tool_function,
                    "schema": mod.tool_schema
                }
                logging.info(f"âœ… åŠ è½½ Skill (py): {tool_name} | æ¥è‡ª: {rel_path}")
            else:
                logging.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆ Skill æ–‡ä»¶: {rel_path} (ç¼ºå°‘ tool_function æˆ– tool_schema)")

        except Exception as e:
            logging.error(f"âŒ åŠ è½½ Skill å¤±è´¥: {py_file} | é”™è¯¯: {e}")

    # âœ… é€’å½’æ‰«ææ‰€æœ‰ .md æ–‡ä»¶
    md_files = glob.glob(os.path.join(skills_dir, "**/*.md"), recursive=True)

    for md_file in md_files:
        try:
            rel_path = os.path.relpath(md_file, skills_dir)
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    shared_knowledge.append(f"### ğŸ“š æ¥è‡ª {rel_path} ###\n{content}")
                    logging.info(f"ğŸ“š åŠ è½½çŸ¥è¯†æ–‡ä»¶ (md): {rel_path}")
        except Exception as e:
            logging.error(f"âŒ è¯»å–çŸ¥è¯†æ–‡ä»¶å¤±è´¥: {md_file} | é”™è¯¯: {e}")

    # âœ… ç»Ÿè®¡ä¿¡æ¯
    logging.info(f"ğŸ“Š Skills åŠ è½½å®Œæˆ: {len(tool_registry)} ä¸ªå·¥å…·, {len(shared_knowledge)} ä¸ªçŸ¥è¯†æ–‡ä»¶")

    # âœ… å°†åˆ—è¡¨åˆå¹¶ä¸ºå­—ç¬¦ä¸²
    shared_knowledge_str = "\n\n".join(shared_knowledge)

    return tool_registry, shared_knowledge_str

# ====================== Agent ç±» ======================
class Agent:
    """å•ä¸ªæ™ºèƒ½ä½“ä»£ç†"""

    def __init__(
            self,
            config: Dict,
            default_model: str,
            default_max_tokens: int,
            tool_registry: Dict,
            shared_knowledge: str = "",
            vector_memory: Optional[VectorMemory] = None
    ):
        self.name = config["name"]
        self.role = config["role"]
        self.shared_knowledge = shared_knowledge
        self.vector_memory = vector_memory

        # OpenAI å®¢æˆ·ç«¯é…ç½®
        self.client = OpenAI(
            api_key=config.get("api_key"),
            base_url=config.get("base_url")
        )
        self.model = config.get("model", default_model)
        self.temperature = config.get("temperature", 0.7)
        self.stream = config.get("stream", False)
        self.max_tokens = config.get("max_tokens", default_max_tokens)

        # å·¥å…·é…ç½®
        enabled = config.get("enabled_tools", [])
        self.tools = [
            tool_registry[name]["schema"]
            for name in enabled
            if name in tool_registry
        ]
        self.tool_map = {
            name: tool_registry[name]["func"]
            for name in enabled
            if name in tool_registry
        }

        if self.tools:
            logging.debug(f"  {self.name} å·²å¯ç”¨å·¥å…·: {list(self.tool_map.keys())}")

    def _execute_tool(self, tool_call) -> Dict:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        func_name = tool_call.function.name

        try:
            args = json.loads(tool_call.function.arguments)
            logging.info(f"ğŸ”§ {self.name} è°ƒç”¨å·¥å…·: {func_name}({args})")

            result = self.tool_map[func_name](**args)

            return {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": func_name,
                "content": str(result)
            }
        except Exception as e:
            logging.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥ {func_name}: {e}")
            return {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": func_name,
                "content": f"Tool error: {str(e)}"
            }

    def generate_response(
            self,
            history: List[Dict],
            round_num: int,
            system_extra: str = "",
            force_non_stream: bool = False
    ) -> str:
        """
        ç”Ÿæˆå“åº”
        æ³¨æ„ï¼šå›¾åƒå·²åœ¨ history ä¸­ï¼Œæ— éœ€å•ç‹¬ä¼ é€’
        """
        # âœ… æ·»åŠ è®¡æ—¶
        start_time = time.time()

        use_stream = self.stream and not force_non_stream and not self.tools

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = (
            f"{self.role}\n"
            f"{self.shared_knowledge}\n"
            f"{system_extra}\n"
            "ä½ æ˜¯å¤šæ™ºèƒ½ä½“åä½œå›¢é˜Ÿçš„ä¸€å‘˜,è¯·æä¾›æœ‰ä»·å€¼ã€å‡†ç¡®ã€æœ‰æ·±åº¦çš„è´¡çŒ®ã€‚"
        )

        messages = [{"role": "system", "content": system_prompt}]

        # å¤„ç†å†å²æ¶ˆæ¯
        for h in history:
            if h["speaker"] == "User":
                messages.append({"role": "user", "content": h["content"]})
            elif h["speaker"] == "System":
                # ç³»ç»Ÿæ¶ˆæ¯ç›´æ¥æ·»åŠ 
                messages.append({"role": "system", "content": h["content"]})
            else:
                # å…¶ä»– Agent çš„æ¶ˆæ¯ä½œä¸º assistant æ¶ˆæ¯
                messages.append({
                    "role": "assistant",
                    "content": f"[{h['speaker']}] {h.get('content', '')}"
                })

        try:
            if use_stream:
                print(f"\nğŸ’¬ ã€{self.name}ã€‘æ­£åœ¨æ€è€ƒ... ", end="", flush=True)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                tools=self.tools if self.tools else None,
                tool_choice="auto" if self.tools else None,
                stream=use_stream,
            )

            full_response = ""

            # æµå¼è¾“å‡º
            if use_stream:
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        delta = chunk.choices[0].delta.content
                        print(delta, end="", flush=True)
                        full_response += delta
                print()
            else:
                full_response = response.choices[0].message.content or ""

            # å·¥å…·è°ƒç”¨å¤„ç†
            if (not use_stream and
                    hasattr(response.choices[0].message, 'tool_calls') and
                    response.choices[0].message.tool_calls):

                messages.append(response.choices[0].message.model_dump())

                for tool_call in response.choices[0].message.tool_calls:
                    tool_result = self._execute_tool(tool_call)
                    messages.append(tool_result)

                # è·å–å·¥å…·è°ƒç”¨åçš„æœ€ç»ˆå“åº”
                final_resp = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    stream=False
                )
                full_response = final_resp.choices[0].message.content or ""

            # âœ… è®¡ç®—å¹¶æ˜¾ç¤ºè€—æ—¶
            elapsed = time.time() - start_time
            elapsed_str = f"{elapsed:.2f}ç§’" if elapsed < 60 else f"{int(elapsed // 60)}åˆ†{elapsed % 60:.1f}ç§’"

            if not use_stream:
                print(f"â±ï¸  ã€{self.name}ã€‘å“åº”å®Œæˆ | è€—æ—¶: {elapsed_str}")

            logging.info(f"â±ï¸  {self.name} å“åº”è€—æ—¶: {elapsed_str}")

            return full_response.strip()

        except Exception as e:
            elapsed = time.time() - start_time
            err = f"[Error in {self.name}]: {str(e)}"
            logging.error(f"{err} | è€—æ—¶: {elapsed:.2f}ç§’")
            print(f"âŒ ã€{self.name}ã€‘æ‰§è¡Œå¤±è´¥ | è€—æ—¶: {elapsed:.2f}ç§’")
            return err


# ====================== ä¸»ç±» MultiAgentSwarm ======================
class MultiAgentSwarm:
    """å¤šæ™ºèƒ½ä½“ç¾¤æ™ºæ…§æ¡†æ¶"""

    def __init__(self, config_path: str = "swarm_config.yaml"):
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        with open(config_path, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f)

        # OpenAI é…ç½®
        oai = cfg.get("openai", {})
        self.default_model = oai.get("default_model", "gpt-4o-mini")
        self.default_max_tokens = oai.get("default_max_tokens", 4096)

        # Swarm é…ç½®
        swarm = cfg.get("swarm", {})
        self.mode = swarm.get("mode", "fixed")
        self.max_rounds = swarm.get("max_rounds", 3 if self.mode == "fixed" else 10)
        self.reflection_planning = swarm.get("reflection_planning", True)
        self.enable_web_search = swarm.get("enable_web_search", False)
        self.max_images = swarm.get("max_images", 2)

        self.log_file = swarm.get("log_file", "swarm.log")
        self.skills_dir = swarm.get("skills_dir", "skills")
        self.memory_file = swarm.get("memory_file", "memory.json")
        self.max_memory_items = swarm.get("max_memory_items", 50)

        self.max_reflection_rounds = swarm.get("max_reflection_rounds", 3)
        self.reflection_quality_threshold = swarm.get("reflection_quality_threshold", 9)
        self.stop_quality_threshold = swarm.get("stop_quality_threshold", 8)
        self.quality_convergence_delta = swarm.get("quality_convergence_delta", 0.5)

        # æ—¥å¿—é…ç½®
        logging.basicConfig(
            filename=self.log_file,
            level=logging.INFO,
            format="%(asctime)s | %(levelname)s | %(message)s",
            encoding="utf-8",
            force=True
        )
        logging.getLogger().addHandler(logging.StreamHandler())

        logging.info(f"{'=' * 80}")
        logging.info(f"ğŸš€ MultiAgentSwarm v2.9.1 åˆå§‹åŒ–")
        logging.info(f"   Mode: {self.mode} | Max Rounds: {self.max_rounds}")
        logging.info(f"   Reflection: {self.reflection_planning} | Web Search: {self.enable_web_search}")
        logging.info(f"{'=' * 80}")

        # åŠ è½½ Skills
        self.tool_registry, self.shared_knowledge = load_skills(self.skills_dir)

        # æ·»åŠ å†…ç½®ç½‘ç»œæœç´¢å·¥å…·
        if self.enable_web_search:
            self.tool_registry["web_search"] = {
                "func": web_search,
                "schema": {
                    "type": "function",
                    "function": {
                        "name": "web_search",
                        "description": "å®æ—¶ç½‘é¡µæœç´¢æœ€æ–°ä¿¡æ¯ï¼ˆDuckDuckGoï¼‰",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"},
                                "num_results": {"type": "integer", "description": "è¿”å›ç»“æœæ•°é‡", "default": 5}
                            },
                            "required": ["query"]
                        }
                    }
                }
            }
            logging.info("âœ… å·²å¯ç”¨ç½‘ç»œæœç´¢å·¥å…·")

        # âœ… å…³é”®ä¿®å¤ï¼šå…ˆåˆå§‹åŒ–æŒä¹…åŒ–è®°å¿†ï¼ˆå¿…é¡»åœ¨å‘é‡è®°å¿†ä¹‹å‰ï¼‰
        self.memory = self._load_memory()

        # åˆå§‹åŒ–å‘é‡è®°å¿†
        self.vector_memory = VectorMemory()

        # åˆå§‹åŒ– Agents
        self.agents = []
        for a_cfg in cfg.get("agents", [])[:swarm.get("num_agents", 4)]:
            agent = Agent(
                a_cfg,
                self.default_model,
                self.default_max_tokens,
                self.tool_registry,
                self.shared_knowledge,
                self.vector_memory
            )
            self.agents.append(agent)
            logging.info(f"âœ… Agent åŠ è½½: {agent.name} | Model: {agent.model}")

        if not self.agents:
            raise ValueError("âŒ è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ª Agent")

        self.leader = self.agents[0]
        logging.info(f"ğŸ‘‘ Leader: {self.leader.name}")

    def _load_memory(self) -> Dict:
        """åŠ è½½æŒä¹…åŒ–è®°å¿†"""
        if os.path.exists(self.memory_file):
            try:
                with open(self.memory_file, "r", encoding="utf-8") as f:
                    memory = json.load(f)
                logging.info(f"ğŸ“– åŠ è½½è®°å¿†æ–‡ä»¶: {self.memory_file} ({len(memory)} keys)")
                return memory
            except Exception as e:
                logging.error(f"åŠ è½½è®°å¿†å¤±è´¥: {e}")
        return {}

    def _save_memory(self, key: str, summary: str):
        """ä¿å­˜è®°å¿†åˆ°æŒä¹…åŒ–æ–‡ä»¶"""
        if key not in self.memory:
            self.memory[key] = []

        self.memory[key].append({
            "timestamp": datetime.now().isoformat(),
            "summary": summary[:3000]  # é™åˆ¶é•¿åº¦
        })

        # é™åˆ¶æ¯ä¸ª key çš„è®°å¿†æ•°é‡
        if len(self.memory[key]) > self.max_memory_items:
            self.memory[key] = self.memory[key][-self.max_memory_items:]

        try:
            with open(self.memory_file, "w", encoding="utf-8") as f:
                json.dump(self.memory, f, ensure_ascii=False, indent=2)
            logging.info(f"ğŸ’¾ ä¿å­˜è®°å¿†: {key}")
        except Exception as e:
            logging.error(f"ä¿å­˜è®°å¿†å¤±è´¥: {e}")

    def solve(
            self,
            task: str,
            use_memory: bool = False,
            memory_key: str = "default",
            image_paths: Optional[List[str]] = None
    ) -> str:
        """
        è§£å†³ä»»åŠ¡çš„ä¸»å…¥å£

        Args:
            task: ä»»åŠ¡æè¿°
            use_memory: æ˜¯å¦ä½¿ç”¨æŒä¹…åŒ–è®°å¿†
            memory_key: è®°å¿†é”®å
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆæœ€å¤š max_images å¼ ï¼‰

        Returns:
            æœ€ç»ˆç­”æ¡ˆ
        """
        # âœ… åˆå§‹åŒ–æ—¶é—´è¿½è¸ªå™¨
        tracker = TimeTracker()
        tracker.start()

        logging.info(f"\n{'=' * 80}")
        logging.info(f"ğŸ“‹ æ–°ä»»åŠ¡: {task}")
        logging.info(f"   è®°å¿†æ¨¡å¼: {use_memory} | Key: {memory_key}")
        logging.info(f"   å›¾ç‰‡æ•°é‡: {len(image_paths) if image_paths else 0}")
        logging.info(f"{'=' * 80}")

        print(f"\n{'=' * 80}")
        print(f"ğŸš€ ä»»åŠ¡å¼€å§‹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'=' * 80}\n")

        # âœ… ä¿®å¤ï¼šé™åˆ¶å›¾ç‰‡æ•°é‡ï¼ˆä½¿ç”¨é…ç½®ï¼‰
        if image_paths:
            image_paths = image_paths[:self.max_images]
            logging.info(f"ğŸ“· å¤„ç† {len(image_paths)} å¼ å›¾ç‰‡")

        # åˆå§‹åŒ–å¯¹è¯å†å²
        history: List[Dict] = []

        # âœ… ä¿®å¤ï¼šå›¾åƒå¤„ç†é€»è¾‘ï¼ˆåªå¤„ç†ä¸€æ¬¡ï¼Œæ”¾åœ¨ä»»åŠ¡æè¿°ä¸­ï¼‰
        if image_paths:
            image_content = [{"type": "text", "text": task}]

            for idx, path in enumerate(image_paths, 1):
                if not os.path.exists(path):
                    logging.warning(f"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {path}")
                    continue

                try:
                    # åŠ¨æ€æ£€æµ‹ MIME ç±»å‹
                    mime_type, _ = mimetypes.guess_type(path)
                    if not mime_type or not mime_type.startswith("image/"):
                        mime_type = "image/jpeg"

                    with open(path, "rb") as f:
                        base64_image = base64.b64encode(f.read()).decode('utf-8')

                    image_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{base64_image}"
                        }
                    })
                    logging.info(f"  âœ… å›¾ç‰‡ {idx}: {path} ({mime_type})")

                except Exception as e:
                    logging.error(f"  âŒ è¯»å–å›¾ç‰‡å¤±è´¥ {path}: {e}")
                    image_content.append({
                        "type": "text",
                        "text": f"[æ— æ³•è¯»å–å›¾ç‰‡ {idx}: {os.path.basename(path)}]"
                    })

            # å°†å›¾åƒä½œä¸ºç”¨æˆ·æ¶ˆæ¯çš„ä¸€éƒ¨åˆ†
            history.append({"speaker": "User", "content": image_content})
        else:
            history.append({"speaker": "User", "content": task})

        # âœ… è®°å½•æ£€æŸ¥ç‚¹ï¼šåˆå§‹åŒ–å®Œæˆ
        tracker.checkpoint("1ï¸âƒ£ åˆå§‹åŒ–")

        # åŠ è½½å†å²è®°å¿†
        if use_memory and memory_key in self.memory:
            memory_text = "\n".join([
                f"- {item['summary']}"
                for item in self.memory[memory_key][-5:]
            ])
            history.insert(0, {
                "speaker": "System",
                "content": f"ğŸ“š å†å²è®°å¿†ï¼ˆ{memory_key}ï¼‰ï¼š\n{memory_text}"
            })
            logging.info(f"ğŸ“– åŠ è½½å†å²è®°å¿†: {memory_key} ({len(self.memory[memory_key])} æ¡)")

        # ä¸»å¾ªç¯
        round_num = 0
        while True:
            round_num += 1

            if round_num > self.max_rounds:
                logging.warning(f"â±ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡ {self.max_rounds}ï¼Œå¼ºåˆ¶ç»“æŸ")
                break

            logging.info(f"\n{'â”€' * 80}")
            logging.info(f"ğŸ”„ ç¬¬ {round_num} è½®è®¨è®ºå¼€å§‹")
            logging.info(f"{'â”€' * 80}")

            # âœ… è®°å½•è½®æ¬¡å¼€å§‹æ—¶é—´
            round_start = time.time()

            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ Agents
            with ThreadPoolExecutor(max_workers=len(self.agents)) as executor:
                future_to_agent = {
                    executor.submit(
                        agent.generate_response,
                        history.copy(),
                        round_num
                    ): agent
                    for agent in self.agents
                }

                for future in as_completed(future_to_agent):
                    agent = future_to_agent[future]
                    try:
                        contribution = future.result()
                        history.append({
                            "speaker": agent.name,
                            "content": contribution
                        })
                        logging.info(f"âœ… {agent.name} å®Œæˆç¬¬ {round_num} è½®")
                    except Exception as e:
                        logging.error(f"âŒ {agent.name} æ‰§è¡Œå¤±è´¥: {e}")
                        history.append({
                            "speaker": agent.name,
                            "content": f"[æ‰§è¡Œå¤±è´¥: {str(e)}]"
                        })

            # âœ… è®°å½•è½®æ¬¡è€—æ—¶
            round_elapsed = time.time() - round_start
            round_time_str = tracker.format_time(round_elapsed)
            print(f"\nâ±ï¸  ç¬¬ {round_num} è½®è®¨è®ºå®Œæˆ | è€—æ—¶: {round_time_str}\n")
            logging.info(f"â±ï¸  ç¬¬ {round_num} è½®è®¨è®ºè€—æ—¶: {round_time_str}")

            tracker.checkpoint(f"2ï¸âƒ£ ç¬¬{round_num}è½®è®¨è®º")

            # âœ…âœ…âœ… Reflection + Planningï¼ˆå¤šè½®åæ€ä¼˜åŒ–ç‰ˆï¼‰âœ…âœ…âœ…
            if self.mode == "intelligent" and self.reflection_planning:
                reflection_start = time.time()

                logging.info(f"\n{'â”€' * 80}")
                logging.info(f"ğŸ¤” Leader Multi-Round Reflection (ç¬¬ {round_num} è½®)")
                logging.info(f"{'â”€' * 80}")

                # Planningï¼ˆä¿æŒä¸å˜ï¼‰
                plan_prompt = (
                    "è¯·ä»¥ JSON æ ¼å¼è§„åˆ’ä¸‹ä¸€è½®çš„é‡ç‚¹æ–¹å‘ã€‚\n"
                    "æ ¼å¼: {\"focus_areas\": [\"æ–¹å‘1\", \"æ–¹å‘2\"], \"expected_improvement\": \"é¢„æœŸæ”¹è¿›\"}"
                )
                plan = self.leader.generate_response(
                    history + [{"speaker": "System", "content": plan_prompt}],
                    round_num,
                    force_non_stream=True
                )
                logging.info(f"ğŸ“‹ Plan: {plan[:200]}...")

                # âœ… å¤šè½®åæ€å¾ªç¯ï¼ˆæ–°å¢æ ¸å¿ƒé€»è¾‘ï¼‰
                max_reflection_rounds = self.max_reflection_rounds
                final_decision = "continue"
                final_quality = 0
                previous_quality = 0  # ç”¨äºæ£€æµ‹æ”¶æ•›

                for reflection_round in range(1, max_reflection_rounds + 1):
                    logging.info(f"\nğŸ” Reflection Round {reflection_round}/{max_reflection_rounds}")

                    # æ„å»ºåæ€æç¤ºï¼ˆéšè½®æ¬¡æ·±åŒ–ï¼‰
                    if reflection_round == 1:
                        reflect_prompt = (
                            "è¯·åæ€æœ¬è½®è®¨è®ºç»“æœï¼Œç»™å‡ºè´¨é‡è¯„åˆ†å’Œå†³ç­–ã€‚\n"
                            "è¯„ä¼°æ ‡å‡†ï¼š\n"
                            "- ä¿¡æ¯å®Œæ•´æ€§ï¼ˆæ˜¯å¦è¦†ç›–å…³é”®ç‚¹ï¼‰\n"
                            "- é€»è¾‘ä¸¥å¯†æ€§ï¼ˆæ˜¯å¦æœ‰çŸ›ç›¾æˆ–è·³è·ƒï¼‰\n"
                            "- æ·±åº¦ä¸æ´å¯Ÿï¼ˆæ˜¯å¦æœ‰ç‹¬åˆ°è§è§£ï¼‰\n"
                            "JSON æ ¼å¼: {\"quality_score\": 1-10, \"decision\": \"continue/stop\", "
                            "\"reason\": \"åŸå› \", \"suggestions\": [\"å»ºè®®1\", \"å»ºè®®2\"]}"
                        )
                    elif reflection_round == 2:
                        reflect_prompt = (
                            f"è¿™æ˜¯ç¬¬ {reflection_round} æ¬¡æ·±åº¦åæ€ã€‚\n"
                            f"ä¸Šæ¬¡è¯„åˆ†ï¼š{final_quality}/10\n"
                            f"ä¸Šæ¬¡å»ºè®®ï¼šå·²åœ¨è®¨è®ºä¸­éƒ¨åˆ†ä½“ç°\n\n"
                            "è¯·æ›´æ·±å…¥åœ°åˆ†æï¼š\n"
                            "- æ˜¯å¦è¿˜æœ‰éšè—çš„é€»è¾‘æ¼æ´ï¼Ÿ\n"
                            "- è®ºæ®æ˜¯å¦å……åˆ†æ”¯æ’‘ç»“è®ºï¼Ÿ\n"
                            "- è¡¨è¾¾æ˜¯å¦æ¸…æ™°æ˜“æ‡‚ï¼Ÿ\n"
                            "JSON æ ¼å¼: {\"quality_score\": 1-10, \"decision\": \"continue/stop\", "
                            "\"reason\": \"åŸå› \", \"critical_issues\": [\"å…³é”®é—®é¢˜1\", \"å…³é”®é—®é¢˜2\"]}"
                        )
                    else:  # reflection_round == 3
                        reflect_prompt = (
                            f"è¿™æ˜¯ç¬¬ {reflection_round} æ¬¡ï¼ˆæœ€ç»ˆï¼‰åæ€ã€‚\n"
                            f"ä¸Šæ¬¡è¯„åˆ†ï¼š{final_quality}/10\n"
                            f"è´¨é‡æå‡å¹…åº¦ï¼š{final_quality - previous_quality if previous_quality > 0 else 'N/A'}\n\n"
                            "è¯·åšæœ€ç»ˆç»¼åˆåˆ¤æ–­ï¼š\n"
                            "- å½“å‰è´¨é‡æ˜¯å¦è¾¾åˆ°å¯äº¤ä»˜æ ‡å‡†ï¼Ÿ\n"
                            "- ç»§ç»­è®¨è®ºçš„è¾¹é™…æ”¶ç›Šå¦‚ä½•ï¼Ÿ\n"
                            "- æ˜¯å¦å­˜åœ¨è‡´å‘½ç¼ºé™·å¿…é¡»ä¿®å¤ï¼Ÿ\n"
                            "JSON æ ¼å¼: {\"quality_score\": 1-10, \"decision\": \"continue/stop\", "
                            "\"reason\": \"åŸå› \", \"final_verdict\": \"ç»¼åˆè¯„ä»·\"}"
                        )

                    leader_eval = self.leader.generate_response(
                        history + [{"speaker": "System", "content": reflect_prompt}],
                        round_num,
                        force_non_stream=True
                    )

                    logging.info(f"ğŸ’­ Reflection {reflection_round}: {leader_eval[:150]}...")

                    # è§£æè¯„ä¼°ç»“æœ
                    try:
                        eval_json = json.loads(
                            leader_eval.strip()
                            .replace("```json", "")
                            .replace("```", "")
                            .strip()
                        )

                        previous_quality = final_quality  # ä¿å­˜ä¸Šä¸€è½®è¯„åˆ†
                        final_quality = eval_json.get("quality_score", 0)
                        final_decision = eval_json.get("decision", "").lower()

                        logging.info(f"ğŸ“Š è´¨é‡è¯„åˆ†: {final_quality}/10 | å†³ç­–: {final_decision}")

                        # âœ… æå‰ç»ˆæ­¢æ¡ä»¶1ï¼šè´¨é‡æé«˜
                        if final_quality >= self.reflection_quality_threshold:
                            logging.info(f"âœ… è´¨é‡è¾¾åˆ° {final_quality}/10ï¼Œæ— éœ€ç»§ç»­åæ€")
                            break

                        # âœ… æå‰ç»ˆæ­¢æ¡ä»¶2ï¼šæ˜ç¡®åœæ­¢ä¿¡å·
                        if final_decision == "stop" and final_quality >= self.stop_quality_threshold:
                            logging.info(f"âœ… Leader åˆ¤æ–­è´¨é‡ {final_quality}/10 å¯æ¥å—ï¼Œåœæ­¢åæ€")
                            break

                        # âœ… æå‰ç»ˆæ­¢æ¡ä»¶3ï¼šè´¨é‡æ”¶æ•›ï¼ˆå¢å¹… < 0.5ï¼‰
                        if reflection_round > 1 and previous_quality > 0:
                            quality_delta = final_quality - previous_quality
                            if abs(quality_delta) < self.quality_convergence_delta:
                                logging.info(
                                    f"ğŸ”´ è´¨é‡æå‡åœæ» (Î”={quality_delta:.1f})ï¼Œåœæ­¢åæ€"
                                )
                                break

                    except json.JSONDecodeError:
                        logging.warning(f"âš ï¸ åæ€ {reflection_round} JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                        final_quality = max(final_quality, 5)  # ä¿åº•åˆ†æ•°
                        continue
                    except Exception as e:
                        logging.error(f"âŒ åæ€ {reflection_round} å¤„ç†å¤±è´¥: {e}")
                        continue

                # âœ… è®°å½•åæ€è€—æ—¶
                reflection_elapsed = time.time() - reflection_start
                reflection_time_str = tracker.format_time(reflection_elapsed)
                print(f"â±ï¸  åæ€é˜¶æ®µå®Œæˆ | è€—æ—¶: {reflection_time_str}\n")
                logging.info(f"â±ï¸  åæ€é˜¶æ®µè€—æ—¶: {reflection_time_str}")

                tracker.checkpoint(f"3ï¸âƒ£ ç¬¬{round_num}è½®åæ€")

                # âœ… æœ€ç»ˆå†³ç­–ï¼ˆåŸºäºå¤šè½®åæ€çš„ç´¯ç§¯ç»“æœï¼‰
                if final_decision == "stop" and final_quality >= self.stop_quality_threshold:
                    logging.info(
                        f"ğŸ¯ ç»è¿‡ {reflection_round} è½®åæ€ï¼Œè´¨é‡è¾¾åˆ° {final_quality}/10ï¼Œåœæ­¢è®¨è®º"
                    )
                    break
                else:
                    logging.info(
                        f"ğŸ”„ è´¨é‡ {final_quality}/10ï¼Œç»§ç»­ä¸‹ä¸€è½®è®¨è®ºä¼˜åŒ–"
                    )

        # âœ… æœ€ç»ˆç»¼åˆ
        final_synthesis_start = time.time()

        logging.info(f"\n{'=' * 80}")
        logging.info("ğŸ¯ Leader æœ€ç»ˆç»¼åˆ")
        logging.info(f"{'=' * 80}")

        history.append({
            "speaker": "System",
            "content": (
                "è¯·ç»¼åˆä»¥ä¸Šå…¨éƒ¨è®¨è®ºï¼Œç»™å‡ºæœ€å‡†ç¡®ã€æœ€å®Œæ•´ã€æœ€é«˜è´¨é‡çš„æœ€ç»ˆç­”æ¡ˆã€‚\n"
                "è¦æ±‚ï¼š\n"
                "1. é€»è¾‘ä¸¥å¯†ï¼Œè®ºè¯å……åˆ†\n"
                "2. ä¿¡æ¯å®Œæ•´ï¼Œç»†èŠ‚ä¸°å¯Œ\n"
                "3. ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç†è§£\n"
                "4. å¦‚æ¶‰åŠä»£ç æˆ–æ–‡ä»¶æ“ä½œï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®æ‰§è¡Œ"
            )
        })

        final_answer = self.leader.generate_response(
            history,
            round_num + 1,
            force_non_stream=False
        )

        # âœ… è®°å½•æœ€ç»ˆç»¼åˆè€—æ—¶
        final_synthesis_elapsed = time.time() - final_synthesis_start
        tracker.checkpoint("4ï¸âƒ£ æœ€ç»ˆç»¼åˆ")

        # ä¿å­˜è®°å¿†
        if use_memory:
            summary_prompt = (
                "è¯·ç”¨ 500 å­—ä»¥å†…æ€»ç»“æœ¬æ¬¡ä»»åŠ¡çš„ï¼š\n"
                "1. æ ¸å¿ƒç»“è®º\n"
                "2. å…³é”®å‘ç°\n"
                "3. å¯å¤ç”¨ç»éªŒ\n"
                "4. é—ç•™é—®é¢˜ï¼ˆå¦‚æœ‰ï¼‰"
            )
            summary = self.leader.generate_response(
                history + [{"speaker": "System", "content": summary_prompt}],
                round_num + 1,
                force_non_stream=True
            )
            self._save_memory(memory_key, summary)

            # åŒæ—¶ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
            if self.vector_memory:
                self.vector_memory.add(
                    summary,
                    metadata={"task": task[:100], "memory_key": memory_key}
                )

            tracker.checkpoint("5ï¸âƒ£ ä¿å­˜è®°å¿†")

        # è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
        print("\n" + "=" * 100)
        print("ğŸ¯ ã€æœ€ç»ˆæœ€é«˜è´¨é‡ç­”æ¡ˆã€‘")
        print("=" * 100)
        print(final_answer)
        print("=" * 100)

        # âœ… æ˜¾ç¤ºå®Œæ•´è€—æ—¶ç»Ÿè®¡
        print(tracker.summary())
        logging.info(tracker.summary())

        logging.info(f"\n{'=' * 80}")
        logging.info("âœ… ä»»åŠ¡å®Œæˆ")
        logging.info(f"{'=' * 80}\n")

        return final_answer


# ====================== ä¸»å‡½æ•° ======================
if __name__ == "__main__":
    try:
        swarm = MultiAgentSwarm()

        # ç¤ºä¾‹1ï¼šåŸºç¡€ä»»åŠ¡
        # swarm.solve("è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿")

        # ç¤ºä¾‹2ï¼šå¸¦è®°å¿†çš„æ·±åº¦æŠ¥å‘Š
        swarm.solve(
            "è¯·å¸®æˆ‘å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„æ·±åº¦åˆ†ææŠ¥å‘Šï¼Œå¹¶ä¿å­˜åˆ° ./reports/ai_report.md",
            use_memory=True,
            memory_key="ai_topic"
        )

        # ç¤ºä¾‹3ï¼šå›¾åƒåˆ†æï¼ˆéœ€è¦æä¾›çœŸå®å›¾ç‰‡è·¯å¾„ï¼‰
        # swarm.solve(
        #     "è¯·åˆ†æè¿™äº›å›¾ç‰‡ä¸­çš„ä»£ç é—®é¢˜",
        #     image_paths=["./screenshot1.png", "./screenshot2.png"]
        # )

    except Exception as e:
        logging.error(f"âŒ ç¨‹åºå¼‚å¸¸: {e}", exc_info=True)